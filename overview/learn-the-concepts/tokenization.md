# Tokenization

Within the realm of artificial intelligence, tokenization refers to the transformation of information into portions/bits of recurrent data.&#x20;

Known as Byte-pair encoding, tokenization is basically breaking down strings of text into micro-batches of characters and tagging them in such a way that can be adeptly stored and understood by the binary functions of a computer.

Consider the combination of the three letters _i-n-g_. Each letter is an independent token, however, when put together to form “_ing_” they take on a wholly different representation that is commonly found at the tail end of past tense actions (end-ing, mean-ing, vot-ing, etc).&#x20;

Taking this a step further, within the three characters you will also see the ability for a multitude of two-letter combinations for tags such as “ig”, “ng”, “gi” and so on. Each combination of the letters would be its own unique token. By having every possible combination of the individual letters tokenized, it becomes easier to recognize patterns in large datasets rather than having to process each individual letter, individually. For situations where “in” would arise, we know that if the two letters are detached from any other letters then it would classify as a word, however, if they are included with other letters, then we can ignore the word take and operate on the sentence structure more accurately.



\---

**DISCLAIMER**: _The information contained in our whitepaper and roadmap is provided for informational purposes only and should not be construed as financial advice or an inducement to purchase our utility token, $CGPT, for any purpose other than to interact with the ChainGPT AI bot, which is available at the time of the token sale. $CGPT is intended solely for use within the ChainGPT AI ecosystem, and we make no representations or warranties regarding the value, security, or suitability of $CGPT for any other purpose. We strongly encourage you to conduct due diligence and seek professional advice before making investment decisions. By accessing our whitepaper, website, and roadmap, you agree to release and hold us and our affiliates harmless from any liability for using the information.  In addition, please read our_ [Agreement for Sale of Tokens](https://www.chaingpt.org/licences).
