# Fine-Tuning

Fine-tuning is key to the optimization of an AI model's functionality.

From the collection of data to the refinement of it to the processing and production, fine-tuning is an iterative process that selectively extrapolates portions of an AIâ€™s operation and effectively re-trains it to increase the fidelity of its outputs.

Typically implemented through a supervised learning approach where human intervention is required in order to pinpoint discrepancies and guide the AI to understand desired outputs.

As it relates to ChainGPT, fine-tuning is conducted on a regular basis by the development team that is monitoring the qualitative state of ChainGPT. Additionally, fine-tuning may be implemented ad hoc in sudden critical, logical lapses.

\---

**DISCLAIMER**: _The information contained in our whitepaper and roadmap is provided for informational purposes only and should not be construed as financial advice or an inducement to purchase our utility token, $CGPT, for any purpose other than to interact with the ChainGPT AI bot, which is available at the time of the token sale. $CGPT is intended solely for use within the ChainGPT AI ecosystem, and we make no representations or warranties regarding the value, security, or suitability of $CGPT for any other purpose. We strongly encourage you to conduct due diligence and seek professional advice before making investment decisions. By accessing our whitepaper, website, and roadmap, you agree to release and hold us and our affiliates harmless from any liability for using the information.  In addition, please read our_ [Agreement for Sale of Tokens](https://www.chaingpt.org/licences).
